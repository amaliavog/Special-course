{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import infostop\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import osmnx as ox\n",
    "import requests\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "ox.config(use_cache=True, log_console=True)\n",
    "print(ox.__version__)\n",
    "\n",
    "import networkx as nx\n",
    "import geopandas as gpd\n",
    "import multiprocessing as mp\n",
    "\n",
    "from descartes import PolygonPatch\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "\n",
    "import folium\n",
    "from folium.plugins import Fullscreen, HeatMapWithTime, TimestampedGeoJson\n",
    "from folium.plugins import TimestampedGeoJson, HeatMap, HeatMapWithTime\n",
    "\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly_express as px\n",
    "import tqdm\n",
    "from tqdm._tqdm_notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "def print_df(df):\n",
    "    return display(HTML(df.to_html()))\n",
    "\n",
    "stops = pd.read_csv('stops.csv')\n",
    "stops.rename(columns={'loc':'label'}, inplace=True)\n",
    "stops['start'] = pd.to_datetime(stops['start'], unit='ms')\n",
    "stops['end'] = pd.to_datetime(stops['end'], unit='ms')\n",
    "stops['label'] = stops['label'].apply(int)\n",
    "stops['label'] = stops['label'].apply(str)\n",
    "stops['user'] = stops['user'].apply(str)\n",
    "print_df(stops.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oneday = stops.loc[(stops['start'] >= pd.to_datetime('2014-01-01')) & (stops['start'] < pd.to_datetime('2014-01-02')) & ((stops['user'] == '0') | (stops['user'] == '1') | (stops['user'] == '2'))].copy()\n",
    "# print_df(oneday.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Markdown(\"<font color=green> <font size=4>'oneday' dataframe has 3 people's information which has the user labels of 0, 1 and 2.\\\n",
    "#                  \\nShape of this dataframe is {}.\".format(stops.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_data = [[row['lat'],row['lon']] for index, row in stops.iterrows()]\n",
    "map_hooray = folium.Map(location=[55.636413, 11.298542], zoom_start = 3, tiles='Stamen Toner')\n",
    "HeatMap(loc_data, radius = 20, max_zoom = 30).add_to(map_hooray)\n",
    "map_hooray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_median = pd.merge(stops.groupby(by=['label'])['lat'].median().reset_index().copy(), \\\n",
    "                         stops.groupby(by=['label'])['lon'].median().reset_index().copy(), how='outer', on='label')\n",
    "stops_median.rename(columns={'lat':'lat_median', 'lon':'lot_median'}, inplace=True)\n",
    "print_df(stops_median.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_missing(df):\n",
    "    percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "    missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                 'percent_missing': percent_missing})\n",
    "    missing_value_df.sort_values('percent_missing', inplace=True)\n",
    "    missing_value_df.reset_index(drop=True, inplace=True)\n",
    "    return missing_value_df\n",
    "\n",
    "missing_df_median = percent_missing(stops_median)\n",
    "missing_df_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} rows dropped after finding median latitudes and longitudes for each label.'.format(stops.shape[0]-stops_median.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_real = pd.merge(stops, stops_median, on='label', how='left')\n",
    "stops_real.sort_values(by=['start', 'end', 'label'], inplace=True)\n",
    "stops_real.reset_index(drop=True, inplace=True)\n",
    "print_df(stops_real.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green>\n",
    "<font size = 4>\n",
    "\n",
    "- Now, median coordinates are found for each label.\n",
    "- Only media coordinates will be kept and others will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_real.drop(columns=['lat', 'lon'], inplace=True)\n",
    "stops_real.rename(columns={'lat_median':'lat', 'lot_median':'lon'}, inplace=True)\n",
    "stops_real[\"geo\"] = stops_real[\"lat\"].map(str) + \", \" + stops_real[\"lon\"].map(str)\n",
    "print_df(stops_real.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%who DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del stops_median\n",
    "stops_median = stops_real.copy()\n",
    "del missing_df_median, stops, stops_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df_median = percent_missing(stops_median)\n",
    "missing_df_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del missing_df_median\n",
    "print_df(stops_median.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "south = stops_median['lat'].min()\n",
    "north = stops_median['lat'].max()\n",
    "west = stops_median['lon'].min()\n",
    "east = stops_median['lon'].max()\n",
    "tags = {'amenity' : True,\n",
    "        'landuse' : ['retail', 'commercial'],\n",
    "        'highway' : 'bus_stop'}\n",
    "gdf = ox.geometries_from_bbox(north = north, south = south, east = east, west = west, tags = tags)\n",
    "print(gdf.shape)\n",
    "print_df(gdf[gdf['amenity']=='bank'].dropna(axis=1, how='any').head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gdf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### According to GeoPandas [link here](https://geopandas.org/gallery/create_geopandas_from_pandas.html), __*longitude*__ is __*X*__ and __*latitude*__ is __*Y*__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_gdf = gpd.GeoDataFrame(\n",
    "    stops_median, geometry=gpd.points_from_xy(stops_median.lon, stops_median.lat))\n",
    "\n",
    "gdf['center_point'] = gdf['geometry'].map(lambda row: row.centroid)\n",
    "gdf[\"gdf_lon\"] = gdf.center_point.map(lambda row: row.x)\n",
    "gdf[\"gdf_lat\"] = gdf.center_point.map(lambda row: row.y)\n",
    "\n",
    "print_df(gdf[['geometry', 'center_point', 'gdf_lat', 'gdf_lon']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "<font color=green>\n",
    "\n",
    "- My haversine related test functions are as follows;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371000 # Radius of earth in meters. Use 3956 for miles\n",
    "    print('Result in radians:',c, '\\n')\n",
    "    print('Result in m:',c * r, '\\n')\n",
    "\n",
    "print(haversine(11.98057675, 56.00953381, 12.5777652, 55.6180708))\n",
    "\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from math import radians\n",
    "\n",
    "def haversine2(lat1, lon1, lat2, lon2):\n",
    "    row0 = lat1, lon1\n",
    "    row1 = lat2, lon2\n",
    "    row0_in_radians = [radians(_) for _ in row0]\n",
    "    row1_in_radians = [radians(_) for _ in row1]\n",
    "    result = haversine_distances([row0_in_radians, row1_in_radians])\n",
    "    print('Result in radians:\\n',result)\n",
    "    print('Result in m:\\n',result * 6371000)\n",
    "    \n",
    "print(haversine2(11.98057675, 56.00953381, 12.5777652, 55.6180708))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import BallTree\n",
    "from shapely.geometry import Point\n",
    "import functools\n",
    "import operator\n",
    "import numpy as np\n",
    "from math import radians\n",
    "\n",
    "\n",
    "def ball_distance(df, gdf, distance_to_point_meters):\n",
    "    earth_radius = 6371000 # meters in earth\n",
    "    radian_radius = float(distance_to_point_meters / earth_radius)\n",
    "    \n",
    "    array_GDF = np.array(list(gdf.center_point.apply(lambda geo: [geo.y, geo.x])))\n",
    "    list_GDF_rad = [[radians(i[0]), radians(i[1])] for i in array_GDF.tolist()] \n",
    "    array_GDF_rad = np.array(list_GDF_rad)\n",
    "\n",
    "    array_DF = np.array(list(df.geometry.apply(lambda geo: [geo.y, geo.x]))) \n",
    "    list_DF_rad = [[radians(i[0]), radians(i[1])] for i in array_DF.tolist()]\n",
    "    array_DF_rad = np.array(list_DF_rad)\n",
    "\n",
    "    # Tree will be created according to our gdf_df since the closest points will be found out according to these 'triangulations'\n",
    "    leafSize = round(len(array_GDF)) # to guarantee number of leaves\n",
    "\n",
    "    btree = BallTree(array_GDF_rad, metric='haversine', leaf_size=leafSize)\n",
    "    idx, dist = btree.query_radius(X=array_DF_rad, r=radian_radius, return_distance=True, sort_results=True) #query_radius\n",
    "\n",
    "    dist = dist.tolist()\n",
    "    idx = idx.tolist()\n",
    "\n",
    "    dist = [(i[:1] or [np.nan])[0] for i in dist]\n",
    "    idx = [(i[:1] or [np.nan])[0] for i in idx]\n",
    "\n",
    "    idx = [ix for ix in idx if str(ix) != 'nan']\n",
    "    dist = [dt for dt in dist if str(dt) != 'nan']\n",
    "\n",
    "    dist_mt = [dt_r*6371000 for dt_r in dist]\n",
    "\n",
    "    assert len(idx) == len(dist) == len(dist_mt)\n",
    "    \n",
    "    gdf_final = pd.concat([df.reset_index(drop=True), gdf.loc[idx, gdf.columns != 'geometry'].reset_index(drop=True), pd.Series(dist, name='dist'), pd.Series(dist_mt, name='dist_mt')], axis=1)\n",
    "    \n",
    "    return gdf_final, dist, idx\n",
    "\n",
    "distance_gdf, distances, indices = ball_distance(stops_gdf, gdf, 100)  \n",
    "imp_params = ['label','start','end','user','lat','lon','geo','geometry', 'center_point','gdf_lat','gdf_lon','dist','dist_mt']\n",
    "print_df(distance_gdf[imp_params].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can check the distance between two locations from [*this link](https://www.geodatasource.com/distance-calculator), too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat1, lon1, lat2, lon2 = distance_gdf.loc[0, 'lat'], distance_gdf.loc[0, 'lon'], distance_gdf.loc[0, 'gdf_lat'], distance_gdf.loc[0, 'gdf_lon']\n",
    "print('For the lat:{} and lon:{} from user df:\\nMatching with osmnx lat:{} and lon:{} nearest:\\n'.format(lat1, lon1, lat2, lon2))\n",
    "print(haversine(lat1, lon1, lat2, lon2))\n",
    "print(haversine2(lat2, lon2, lat1, lon1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "<font color=green>\n",
    "\n",
    "-  __*'ball_distance'*__  function doesn't work because of the __*'r'*__ paramter in __*'query_radius'*__ method.;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "\n",
    "def ball_nearest(df, gdf):\n",
    "    earth_radius = 6371000 # meters in earth\n",
    "\n",
    "    array_DF = np.array(list(df.geometry.apply(lambda geo: [geo.y, geo.x])))\n",
    "    list_DF_rad = [[radians(i[0]), radians(i[1])] for i in array_DF.tolist()] \n",
    "    array_DF_rad = np.array(list_DF_rad)\n",
    "\n",
    "\n",
    "    array_GDF = np.array(list(gdf.center_point.apply(lambda geo: [geo.y, geo.x]))) \n",
    "    list_GDF_rad = [[radians(i[0]), radians(i[1])] for i in array_GDF.tolist()]\n",
    "    array_GDF_rad = np.array(list_GDF_rad)\n",
    "\n",
    "    leafSize = round(len(array_GDF_rad))\n",
    "    \n",
    "    btree = BallTree(array_GDF_rad, metric='haversine', leaf_size=leafSize)\n",
    "    # Query will be conducted for the 'User' data.\n",
    "    dist, idx = btree.query(array_DF_rad, k=1) \n",
    "    idx = functools.reduce(operator.iconcat, idx, [])\n",
    "    dist = functools.reduce(operator.iconcat, dist, [])\n",
    "    dist_mt = [dt_r*6371000 for dt_r in dist]\n",
    "\n",
    "    gdf_final = pd.concat([oneday_gdf.reset_index(drop=True), gdf.loc[idx, gdf.columns != 'geometry'].reset_index(drop=True), pd.Series(dist, name='dist'),  pd.Series(dist_mt, name='dist_mt')], axis=1)\n",
    "\n",
    "    \n",
    "    return gdf_final, dist, idx\n",
    "\n",
    "nearest_gdf, distances, indices = ball_nearest(stops_gdf, gdf)\n",
    "print_df(nearest_gdf[imp_params].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat1, lon1, lat2, lon2 = nearest_gdf.loc[0, 'lat'], nearest_gdf.loc[0, 'lon'], nearest_gdf.loc[0, 'gdf_lat'], nearest_gdf.loc[0, 'gdf_lon']\n",
    "print('For the lat:{} and lon:{} from user df:\\nMatching with osmnx lat:{} and lon:{} nearest:\\n'.format(lat1, lon1, lat2, lon2))\n",
    "print(haversine(lat1, lon1, lat2, lon2))\n",
    "print(haversine2(lat2, lon2, lat1, lon1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "<font color=green>\n",
    "\n",
    "-  __*'ball_nearest'*__  function works. If we want to select a radius, I can filter data frame either in function or later on outside the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example from the stackoverflow link. \n",
    "### Exact example doesn't work but I fixed it in the next cell.\n",
    "\n",
    "<font size=4>\n",
    "\n",
    "    \n",
    "[Click for the link](https://stackoverflow.com/questions/56862277/interpreting-sklearn-haversine-outputs-to-kilometers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import BallTree\n",
    "earth_radius = 6371000 # meters in earth\n",
    "test_radius = 10 # meters\n",
    "radian_radius = float(test_radius/earth_radius)\n",
    "test_points = [[32.027240,41.981876],[-81.093190,-87.969982]]\n",
    "test_points_rad = [[x[0] * np.pi / 180, x[1] * np.pi / 180] for x in test_points]\n",
    "\n",
    "tree = BallTree(np.array([test_points_rad[0]]), metric = 'haversine')\n",
    "index__, dis__ = tree.query_radius([test_points_rad[1]], r=radian_radius, return_distance  = True)\n",
    "print(index__)\n",
    "print(dis__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import BallTree\n",
    "earth_radius = 6371000 # meters in earth\n",
    "test_radius = 14172980.8 # meters\n",
    "\n",
    "test_points = [[32.027240,41.981876],[-81.093190,-87.969982]]\n",
    "test_points_rad = [[x[0] * np.pi / 180, x[1] * np.pi / 180] for x in test_points]\n",
    "\n",
    "tree = BallTree(np.array([test_points_rad[0]]), metric = 'haversine')\n",
    "index__, dis__ = tree.query_radius([test_points_rad[1]], r=test_radius/earth_radius, return_distance  = True)\n",
    "print(index__)\n",
    "print(dis__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import BallTree\n",
    "earth_radius = 6371000 # meters in earth\n",
    "test_radius = 14172980.6 # meters\n",
    "\n",
    "test_points = [[32.027240,41.981876],[-81.093190,-87.969982]]\n",
    "test_points_rad = [[x[0] * np.pi / 180, x[1] * np.pi / 180] for x in test_points]\n",
    "\n",
    "tree = BallTree(np.array([test_points_rad[0]]), metric = 'haversine')\n",
    "index__, dis__ = tree.query_radius([test_points_rad[1]], r=test_radius/earth_radius, return_distance  = True)\n",
    "print(index__)\n",
    "print(dis__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "<font color=green>\n",
    "\n",
    "-  __*'query_radius'*__  method didn't work in our case even if the all steps are correct. Reason is that, it is pushing tree to create a somehow make wrong decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green>\n",
    "<font size = 5>\n",
    "\n",
    "__*USE THIS TO RE-PRODUCE IPYNB WITHOUT OUTPUT*__\n",
    "    \n",
    "<font size=3>\n",
    "<font color = blue>\n",
    "jupyter nbconvert my_input_notebook.ipynb --to notebook --ClearOutputPreprocessor.enabled=True --stdout > my_output_notebook.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save nearest_gdf to .csv, it includes data for one day and 3 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_gdf.to_csv('gdf_onemonth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
